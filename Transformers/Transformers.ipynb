{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOjLr1a9oaY1"
      },
      "source": [
        "#  Transformers\n",
        "\n",
        "- Angel Molina\n",
        "- Daniel Marin\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B0520y7twc9H"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsuIZcXPwnQQ",
        "outputId": "4ff049a6-1ad7-4632-9f5a-f70c6a1e3d90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F6tYzI4bwmXd"
      },
      "outputs": [],
      "source": [
        "# small toy dataset with English-Spanish sentence pairs\n",
        "english_sentences = [\n",
        "    \"hello\",\n",
        "    \"how are you\",\n",
        "    \"good morning\",\n",
        "    \"i am from ecuador\",\n",
        "    \"thank you\"\n",
        "]\n",
        "\n",
        "spanish_sentences = [\n",
        "    \"hola\",\n",
        "    \"como estas\",\n",
        "    \"buenos dias\",\n",
        "    \"soy de ecuador\",\n",
        "    \"gracias\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcCHDD-ywvIO",
        "outputId": "cbce58f0-9800-42f1-b5a5-3f633f870074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English Vocab: {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3, 'hello': 4, 'how': 5, 'are': 6, 'you': 7, 'good': 8, 'morning': 9, 'i': 10, 'am': 11, 'from': 12, 'ecuador': 13, 'thank': 14}\n",
            "Spanish Vocab: {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3, 'hola': 4, 'como': 5, 'estas': 6, 'buenos': 7, 'dias': 8, 'soy': 9, 'de': 10, 'ecuador': 11, 'gracias': 12}\n"
          ]
        }
      ],
      "source": [
        "# Tokenizer functions\n",
        "def tokenize_en(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "def tokenize_es(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "# Special tokens for padding, start, end, and unknown tokens\n",
        "SPECIAL_TOKENS = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n",
        "\n",
        "# Create vocabulary\n",
        "def build_vocab(sentences, tokenizer):\n",
        "    vocab = SPECIAL_TOKENS.copy()\n",
        "    idx = len(vocab)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        tokens = tokenizer(sentence)\n",
        "        for token in tokens:\n",
        "            if token not in vocab:\n",
        "                vocab[token] = idx\n",
        "                idx += 1\n",
        "\n",
        "    return vocab\n",
        "\n",
        "# Build vocab for English and Spanish\n",
        "english_vocab = build_vocab(english_sentences, tokenize_en)\n",
        "spanish_vocab = build_vocab(spanish_sentences, tokenize_es)\n",
        "\n",
        "print(\"English Vocab:\", english_vocab)\n",
        "print(\"Spanish Vocab:\", spanish_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eAgp9C7dw2E0"
      },
      "outputs": [],
      "source": [
        "# Translation dataset class\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_sentences, trg_sentences, src_tokenizer, trg_tokenizer, src_vocab, trg_vocab):\n",
        "        self.src_sentences = src_sentences\n",
        "        self.trg_sentences = trg_sentences\n",
        "        self.src_tokenizer = src_tokenizer\n",
        "        self.trg_tokenizer = trg_tokenizer\n",
        "        self.src_vocab = src_vocab\n",
        "        self.trg_vocab = trg_vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = self.src_tokenizer(self.src_sentences[idx])\n",
        "        trg = self.trg_tokenizer(self.trg_sentences[idx])\n",
        "\n",
        "        # Convert tokens to indices\n",
        "        src_indices = [self.src_vocab.get(token, self.src_vocab[\"<unk>\"]) for token in src]\n",
        "        trg_indices = [self.trg_vocab.get(token, self.trg_vocab[\"<unk>\"]) for token in trg]\n",
        "\n",
        "        # Add <sos> and <eos> tokens\n",
        "        src_indices = [self.src_vocab[\"<sos>\"]] + src_indices + [self.src_vocab[\"<eos>\"]]\n",
        "        trg_indices = [self.trg_vocab[\"<sos>\"]] + trg_indices + [self.trg_vocab[\"<eos>\"]]\n",
        "\n",
        "        return torch.tensor(src_indices), torch.tensor(trg_indices)\n",
        "\n",
        "# Create dataset and DataLoader\n",
        "train_dataset = TranslationDataset(english_sentences, spanish_sentences, tokenize_en, tokenize_es, english_vocab, spanish_vocab)\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, trg_batch = zip(*batch)\n",
        "\n",
        "    # Pad sequences\n",
        "    src_padded = pad_sequence(src_batch, padding_value=english_vocab[\"<pad>\"])\n",
        "    trg_padded = pad_sequence(trg_batch, padding_value=spanish_vocab[\"<pad>\"])\n",
        "\n",
        "    return src_padded, trg_padded\n",
        "\n",
        "\n",
        "# Create DataLoader with the custom collate function\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "B85o02d6w8CC"
      },
      "outputs": [],
      "source": [
        "# Positional Encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size: int, maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(maxlen, emb_size)\n",
        "        position = torch.arange(0, maxlen, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, emb_size, 2).float() * (-math.log(10000.0) / emb_size))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "p-h8VdHaw7AL"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, emb_dim, n_heads, n_layers, forward_dim, dropout):\n",
        "        super(TransformerModel, self).__init__()\n",
        "\n",
        "        self.src_embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.trg_embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.positional_encoding = PositionalEncoding(emb_dim)\n",
        "\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=emb_dim,\n",
        "            nhead=n_heads,\n",
        "            num_encoder_layers=n_layers,\n",
        "            num_decoder_layers=n_layers,\n",
        "            dim_feedforward=forward_dim,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        self.fc_out = nn.Linear(emb_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, trg, src_mask, trg_mask):\n",
        "        src_emb = self.dropout(self.src_embedding(src)) * math.sqrt(src.shape[1])\n",
        "        trg_emb = self.dropout(self.trg_embedding(trg)) * math.sqrt(trg.shape[1])\n",
        "\n",
        "        src_emb = self.positional_encoding(src_emb)\n",
        "        trg_emb = self.positional_encoding(trg_emb)\n",
        "\n",
        "        # Transformer expects input as [seq_len, batch_size, emb_dim]\n",
        "        src_emb = src_emb.permute(1, 0, 2)\n",
        "        trg_emb = trg_emb.permute(1, 0, 2)\n",
        "\n",
        "        # Ensure masks are of appropriate size\n",
        "        src_mask = src_mask.to(src_emb.device) if src_mask is not None else None\n",
        "        trg_mask = trg_mask.to(trg_emb.device) if trg_mask is not None else None\n",
        "\n",
        "        output = self.transformer(src_emb, trg_emb, src_mask=src_mask, tgt_mask=trg_mask)\n",
        "        output = self.fc_out(output)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "P-DZYN35w_gA"
      },
      "outputs": [],
      "source": [
        "# Helper functions for masking\n",
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8FkAkryExD4z"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    for i, (src, trg) in enumerate(iterator):\n",
        "        src = src.transpose(0, 1).to(device)\n",
        "        trg = trg.transpose(0, 1).to(device)\n",
        "\n",
        "        trg_input = trg[:-1, :]\n",
        "\n",
        "        src_mask = generate_square_subsequent_mask(src.size(1)).to(device)\n",
        "        trg_mask = generate_square_subsequent_mask(trg_input.size(0)).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg_input, src_mask, trg_mask)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output.view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "AJ37GBtwnC-e"
      },
      "outputs": [],
      "source": [
        "# Translation function\n",
        "def translate_sentence(sentence, model, src_vocab, trg_vocab, max_len=10):\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize the input sentence\n",
        "    tokens = tokenize_en(sentence)\n",
        "    src_indices = [src_vocab.get(token, src_vocab[\"<unk>\"]) for token in tokens]\n",
        "    src_indices = [src_vocab[\"<sos>\"]] + src_indices + [src_vocab[\"<eos>\"]]\n",
        "\n",
        "    # Convert to tensor and pass through the encoder\n",
        "    src_tensor = torch.LongTensor(src_indices).unsqueeze(1).to(device)\n",
        "    src_mask = generate_square_subsequent_mask(len(src_tensor)).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        src_emb = model.positional_encoding(model.src_embedding(src_tensor))\n",
        "        memory = model.transformer.encoder(src_emb, src_mask)\n",
        "\n",
        "    trg_indices = [trg_vocab[\"<sos>\"]]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        trg_tensor = torch.LongTensor([trg_indices[-1]]).unsqueeze(1).to(device)\n",
        "        trg_mask = generate_square_subsequent_mask(len(trg_indices)).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            trg_emb = model.positional_encoding(model.trg_embedding(trg_tensor))\n",
        "            output = model.transformer.decoder(trg_emb, memory, trg_mask)\n",
        "\n",
        "        pred_token = output.argmax(2)[-1, :].item()\n",
        "        trg_indices.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_vocab[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    trg_tokens = [list(trg_vocab.keys())[list(trg_vocab.values()).index(idx)] for idx in trg_indices[1:-1]]\n",
        "\n",
        "    return ' '.join(trg_tokens)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bVbyVurNxH3q"
      },
      "outputs": [],
      "source": [
        "# Model parameters\n",
        "INPUT_DIM = len(english_vocab)\n",
        "OUTPUT_DIM = len(spanish_vocab)\n",
        "EMB_DIM = 256\n",
        "N_HEADS = 8\n",
        "N_LAYERS = 3\n",
        "FORWARD_DIM = 512\n",
        "DROPOUT = 0.1\n",
        "\n",
        "# Instantiate the model, optimizer, and loss function\n",
        "model = TransformerModel(INPUT_DIM, OUTPUT_DIM, EMB_DIM, N_HEADS, N_LAYERS, FORWARD_DIM, DROPOUT).to(device)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=english_vocab[\"<pad>\"])\n",
        "\n",
        "# Train the model for a few epochs\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "JfG0jIwSxJAU",
        "outputId": "66e11b07-035c-4a47-a167-d9666a33fcb4"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "the batch number of src and tgt must be equal",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-86e1ff547df5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch+1} | Train Loss: {train_loss:.3f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Test the model by translating a sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-e8dee962a286>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-6bb0a5fea195>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, src_mask, trg_mask)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtrg_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrg_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrg_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrg_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrg_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mis_batched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_batched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the batch number of src and tgt must be equal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_batched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the batch number of src and tgt must be equal\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: the batch number of src and tgt must be equal"
          ]
        }
      ],
      "source": [
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
        "    print(f'Epoch {epoch+1} | Train Loss: {train_loss:.3f}')\n",
        "\n",
        "# Test the model by translating a sentence\n",
        "translated_sentence = translate_sentence(\"hi from ecuador\", model, english_vocab, spanish_vocab)\n",
        "print(f'Translation: {translated_sentence}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
